{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process\n",
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mThread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mgroup\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtarget\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mkwargs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdaemon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "A class that represents a thread of control.\n",
      "\n",
      "This class can be safely subclassed in a limited fashion. There are two ways\n",
      "to specify the activity: by passing a callable object to the constructor, or\n",
      "by overriding the run() method in a subclass.\n",
      "\u001b[1;31mInit docstring:\u001b[0m\n",
      "This constructor should always be called with keyword arguments. Arguments are:\n",
      "\n",
      "*group* should be None; reserved for future extension when a ThreadGroup\n",
      "class is implemented.\n",
      "\n",
      "*target* is the callable object to be invoked by the run()\n",
      "method. Defaults to None, meaning nothing is called.\n",
      "\n",
      "*name* is the thread name. By default, a unique name is constructed of\n",
      "the form \"Thread-N\" where N is a small decimal number.\n",
      "\n",
      "*args* is the argument tuple for the target invocation. Defaults to ().\n",
      "\n",
      "*kwargs* is a dictionary of keyword arguments for the target\n",
      "invocation. Defaults to {}.\n",
      "\n",
      "If a subclass overrides the constructor, it must make sure to invoke\n",
      "the base class constructor (Thread.__init__()) before doing anything\n",
      "else to the thread.\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\users\\rachi\\desktop\\inueuron\\personal projects\\phishing-domain-detection-using-machine-learning\\venv\\lib\\threading.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     Timer, _MainThread, _DummyThread, HBChannel, HistorySavingThread, BackgroundJobBase, ControlThread, Heartbeat, PyDBDaemonThread, ParentPollerUnix, ...\n"
     ]
    }
   ],
   "source": [
    "Thread?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class demo_thread(Thread):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(daemon=False, name = \"demo_thread\")\n",
    "        \n",
    "    def print_msg(self):\n",
    "        time.sleep(5)\n",
    "        print(\"Called by Thread\")\n",
    "        \n",
    "    def run(self):\n",
    "        self.print_msg()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating object of demo thread\n",
      "Starting demo thread\n",
      "Thread created successfully\n",
      "Called by Thread\n",
      "Thread completed successfully\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating object of demo thread\")\n",
    "d = demo_thread()\n",
    "print(\"Starting demo thread\")\n",
    "d.start() ## calls the run method of custom thread class\n",
    "print(\"Thread created successfully\") \n",
    "d.join() ## waits for the thread to finish(waits for other thread to finish itself)\n",
    "print(\"Thread completed successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doing this so that running of training pipeline doesn't block the execution of code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiazing named tuples as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment = namedtuple(\"Experiment\",[\n",
    "    \"experiment_id\",\"initialization_timestamp\", \"artifact_timestamp\",\n",
    "    \"running_status\", \"start_time\",\"stop_time\",\"execution_time\", \"message\", \n",
    "    \"experiment_file_path\", \"custom_threshold\",\"model_f1\",\"model_recall\",\n",
    "    \"model_precision\",\"is_model_accepted\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(*([None]*14)) ## passing as *args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(exp.custom_threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'uuid' from 'c:\\\\Users\\\\rachi\\\\Desktop\\\\inueuron\\\\PERSONAL PROJECTS\\\\Phishing-Domain-Detection-using-Machine-Learning\\\\venv\\\\lib\\\\uuid.py'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "uuid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating ids for experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b8ad457a-e775-4f16-9180-9f055880f996'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(uuid.uuid4()) ## Generates random ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment = namedtuple(\"Experiment\",[\n",
    "    \"experiment_id\",\"initialization_timestamp\", \"artifact_timestamp\",\n",
    "    \"running_status\", \"start_time\",\"stop_time\",\"execution_time\", \"message\", \n",
    "    \"experiment_file_path\", \"custom_threshold\",\"model_f1\",\"model_recall\",\n",
    "    \"model_precision\",\"is_model_accepted\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating dataframes from named tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = namedtuple(\"namedtuple\",[\"input1\", \"input2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_obj = temp(input1=1, input2=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "namedtuple(input1=1, input2=2)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_obj = temp_obj._asdict()\n",
    "# creates dictionary out of the named tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_obj = {key:[value] for key,value in dict_obj.items()}\n",
    "# keys serve as column names, value is enclosed within [], to create a list of values for easy creation of dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input1': [1], 'input2': [2]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input1</th>\n",
       "      <th>input2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input1  input2\n",
       "0       1       2"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(dict_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Returning last rows of dataframe in descending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.DataFrame(\n",
    "    {\n",
    "        \"col1\":[1,2,3,4,5],\n",
    "        \"col2\":[1,2,3,4,5]\n",
    "    }\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_return = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "4     5     5\n",
       "3     4     4\n",
       "2     3     3"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df.iloc[-1:(-1*rows_to_return)-1:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   col1  col2\n",
       "0     1     1\n",
       "1     2     2\n",
       "2     3     3\n",
       "3     4     4\n",
       "4     5     5"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline with thread class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phishing_domain_detection.component.model_trainer import ModelTrainer\n",
    "from phishing_domain_detection.config.configuration import Configuration\n",
    "from phishing_domain_detection.logger import logging\n",
    "from phishing_domain_detection.exception import Phishing_Exception\n",
    "\n",
    "from phishing_domain_detection.entity.artifact_entity import DataIngestionArtifact, DataTransformationArtifact, DataValidationArtifact, ModelTrainerArtifact, ModelEvaluationArtifact, ModelPusherArtifact\n",
    "\n",
    "\n",
    "from phishing_domain_detection.component.data_ingestion import DataIngestion\n",
    "from phishing_domain_detection.component.data_validation import DataValidation\n",
    "from phishing_domain_detection.component.data_transformation import DataTransformation\n",
    "from phishing_domain_detection.component.model_trainer import ModelTrainer\n",
    "from phishing_domain_detection.component.model_evaluation import ModelEvaluation\n",
    "from phishing_domain_detection.component.model_pusher import ModelPusher\n",
    "import os,sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "from phishing_domain_detection.constants import EXPERIMENT_DIR_NAME, EXPERIMENT_FILE_NAME, CURRENT_TIME_STAMP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "Experiment = namedtuple(\"Experiment\",[\n",
    "    \"experiment_id\",\"initialization_timestamp\", \"artifact_timestamp\",\n",
    "    \"running_status\", \"start_time\",\"stop_time\",\"execution_time\", \"message\", \n",
    "    \"experiment_file_path\", \"custom_threshold\",\"model_f1\",\"model_recall\",\n",
    "    \"model_precision\",\"is_model_accepted\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Pipeline(Thread):\n",
    "    ### declaring class level experiment attributes\n",
    "    experiment = Experiment(*([None]*14)) # declaring all attributes of this class level object as None\n",
    "    experiment_file_path = None # declare the experiment file path as None as of Now\n",
    "    \n",
    "    def __init__(self, config = Configuration()) -> None:\n",
    "        try:\n",
    "            \n",
    "            self.config = config\n",
    "            \n",
    "            os.makedirs(self.config.training_pipeline_config.artifact_dir, exist_ok=True)\n",
    "            ## getting path of experiment file\n",
    "            Pipeline.experiment_file_path = os.path.join(self.config.training_pipeline_config.artifact_dir, EXPERIMENT_DIR_NAME, EXPERIMENT_FILE_NAME)\n",
    "            \n",
    "            super().__init__(daemon=False, name='Pipeline') # calling constructor of parent class\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "    def start_data_ingestion(self) -> DataIngestionArtifact:\n",
    "        try:\n",
    "            data_ingestion = DataIngestion(self.config.get_data_ingestion_config())\n",
    "            return data_ingestion.initiate_data_ingestion()\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "    def start_data_validation(self, data_ingestion_artifact: DataIngestionArtifact) -> DataValidationArtifact:\n",
    "        try:\n",
    "            data_validation = DataValidation(self.config.get_data_validation_config(),data_ingestion_artifact, self.config.get_training_pipeline_config())\n",
    "\n",
    "            return data_validation.initiate_data_validation()\n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "    \n",
    "    def start_data_transformation(self,data_ingestion_artifact: DataIngestionArtifact, data_validation_artifact: DataValidationArtifact):\n",
    "        try:\n",
    "            data_transformation = DataTransformation(\n",
    "                data_transformation_config=self.config.get_data_transformation_config(),\n",
    "                data_ingestion_artifact=data_ingestion_artifact,\n",
    "                data_validation_artifact=data_validation_artifact\n",
    "            )\n",
    "            \n",
    "            return data_transformation.initialize_data_transformation()\n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "    def start_model_trainer(self, data_transformation_artifact: DataTransformationArtifact) -> ModelTrainerArtifact:\n",
    "        try:\n",
    "            model_trainer = ModelTrainer(data_transformation_artifact=data_transformation_artifact, model_trainer_config=self.config.get_model_trainer_config())\n",
    "            \n",
    "            return model_trainer.initialize_model_trainer()\n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "    def start_model_evaluation(self, data_ingestion_artifact: DataIngestionArtifact,\n",
    "                               data_validation_artifact: DataValidationArtifact,\n",
    "                               model_trainer_artifact : ModelTrainerArtifact) -> ModelEvaluationArtifact:\n",
    "        try:\n",
    "            model_eval = ModelEvaluation(\n",
    "                model_evaluation_config=self.config.get_model_evaluation_config(),\n",
    "                data_ingestion_artifact=data_ingestion_artifact,\n",
    "                data_validation_artifact=data_validation_artifact,\n",
    "                model_trainer_artifact=model_trainer_artifact\n",
    "            )\n",
    "            \n",
    "            return model_eval.initiate_model_evaluation()\n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "    def start_model_pusher(self, model_evaluation_artifact: ModelEvaluationArtifact):\n",
    "        try:\n",
    "            model_pusher = ModelPusher(model_pusher_config=self.config.get_model_pusher_config(),\n",
    "                        model_evaluation_artifact=model_evaluation_artifact)\n",
    "            return model_pusher.initiate_model_pusher()\n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "     \n",
    "    def run_pipeline(self):\n",
    "        try:\n",
    "            \n",
    "            ## If pipeline is already running, then don't start another pipeline\n",
    "            if Pipeline.experiment.running_status: ## Pipeline already running, so don't run another pipeline\n",
    "                logging.info(f\"Pipeline already running, skipping this pipeline run.\")\n",
    "                return Pipeline.experiment\n",
    "\n",
    "            logging.info(f\"Pipeline starting\")\n",
    "            \n",
    "            ## generating unique id for this pipeline run\n",
    "            experiment_id = str(uuid.uuid4())\n",
    "            \n",
    "            ## Updating the experiment (which is a class) attribute\n",
    "            Pipeline.experiment = Experiment(\n",
    "                experiment_id=experiment_id,\n",
    "                artifact_timestamp=CURRENT_TIME_STAMP,\n",
    "                initialization_timestamp=CURRENT_TIME_STAMP,\n",
    "                running_status=True,\n",
    "                start_time=datetime.now(),\n",
    "                stop_time=None,\n",
    "                custom_threshold=None,\n",
    "                experiment_file_path=Pipeline.experiment_file_path,\n",
    "                execution_time=None,\n",
    "                message=f\"Pipeline has been started successfully\",\n",
    "                is_model_accepted=None,\n",
    "                model_f1=None,\n",
    "                model_precision=None,\n",
    "                model_recall=None\n",
    "            )\n",
    "            \n",
    "            logging.info(f\"Pipeline experiment: {Pipeline.experiment}\")\n",
    "            \n",
    "            self.save_experiment()\n",
    "            \n",
    "            \n",
    "            \n",
    "            ## Data Ingestion\n",
    "            data_ingestion_artifact = self.start_data_ingestion()\n",
    "            data_validation_artifact = self.start_data_validation(data_ingestion_artifact)\n",
    "            data_transformation_artifact = self.start_data_transformation(data_ingestion_artifact=data_ingestion_artifact, data_validation_artifact= data_validation_artifact)\n",
    "            model_trainer_artifact = self.start_model_trainer(data_transformation_artifact=data_transformation_artifact)\n",
    "            model_evaluation_artifact = self.start_model_evaluation(\n",
    "                data_ingestion_artifact=data_ingestion_artifact,\n",
    "                data_validation_artifact=data_validation_artifact,\n",
    "                model_trainer_artifact=model_trainer_artifact\n",
    "            )\n",
    "            \n",
    "            if model_evaluation_artifact.is_model_accepted:\n",
    "                model_pusher_artifact = self.start_model_pusher(model_evaluation_artifact=model_evaluation_artifact)\n",
    "                logging.info(f\"Model Pusher artifact: {model_pusher_artifact}\")\n",
    "            \n",
    "            else:\n",
    "                logging.info(\"Trained model rejected\")\n",
    "\n",
    "            logging.info(f\"Pipeline Run Completed\")\n",
    "\n",
    "            stop_time = datetime.now()\n",
    "            \n",
    "            Pipeline.experiment = Experiment(\n",
    "                experiment_id=experiment_id,\n",
    "                initialization_timestamp= CURRENT_TIME_STAMP,\n",
    "                artifact_timestamp=CURRENT_TIME_STAMP,\n",
    "                running_status=False,\n",
    "                start_time=Pipeline.experiment.start_time,\n",
    "                stop_time=stop_time,\n",
    "                custom_threshold = model_trainer_artifact.custom_threshold,\n",
    "                execution_time= stop_time - Pipeline.experiment.start_time,\n",
    "                experiment_file_path= Pipeline.experiment.experiment_file_path,\n",
    "                is_model_accepted=model_evaluation_artifact.is_model_accepted,\n",
    "                message=f\"Pipeline has finished executing.\",\n",
    "                model_f1=model_trainer_artifact.model_f1,\n",
    "                model_precision=model_trainer_artifact.model_precision,\n",
    "                model_recall=model_trainer_artifact.model_recall\n",
    "                \n",
    "            )\n",
    "            \n",
    "            logging.info(f\"Pipeline experiment: {Pipeline.experiment}\")\n",
    "            self.save_experiment()\n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "    def run(self):\n",
    "        try:\n",
    "            self.run_pipeline()\n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "    \n",
    "    \n",
    "    def save_experiment(self):\n",
    "        try:\n",
    "            if Pipeline.experiment.experiment_id is None:\n",
    "                print(\"Trigger the pipeline atleast once\")\n",
    "                logging.info(\"Trigger the pipeline first\")\n",
    "                \n",
    "            experiment = Pipeline.experiment\n",
    "            \n",
    "            experiment_dict = experiment._asdict()\n",
    "            \n",
    "            experiment_dict = {key:[value] for key,value in experiment_dict.items()}\n",
    "            # keys serve as column names, value is enclosed within [], to create a list of values for easy creation of dataframe\n",
    "            \n",
    "            experiment_dict.update(\n",
    "                {\n",
    "                    \"created_time_stamp\":[datetime.now()],\n",
    "                    \"experiment_file_path\": [os.path.basename(Pipeline.experiment.experiment_file_path)]\n",
    "                }\n",
    "            )\n",
    "            \n",
    "            experiment_report = pd.DataFrame(experiment_dict)\n",
    "            \n",
    "            os.makedirs(os.path.dirname(Pipeline.experiment.experiment_file_path), exist_ok=True)\n",
    "            \n",
    "            if os.path.exists(Pipeline.experiment.experiment_file_path):\n",
    "                ## Not the first experiment\n",
    "                experiment_report.to_csv(Pipeline.experiment_file_path, index=False, header=False, mode=\"a\")\n",
    "            else:\n",
    "                ## 1st experiment\n",
    "                experiment_report.to_csv(Pipeline.experiment_file_path, mode=\"w\", index=False, header=True) \n",
    "            \n",
    "            \n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e\n",
    "        \n",
    "        \n",
    "    @classmethod\n",
    "    def get_experiments_status(cls, rows_to_return = 5) ->pd.DataFrame:\n",
    "        try:\n",
    "            if os.path.exists(Pipeline.experiment.experiment_file_path):\n",
    "                df = pd.read_csv(Pipeline.experiment_file_path)\n",
    "                return df.iloc[-1:(-1*rows_to_return)-1:-1].drop(columns=[\"experiment_file_path\", \"initialization_timestamp\"], axis=1)\n",
    "            else:\n",
    "                return pd.DataFrame()  # empty dataframess\n",
    "        except Exception as e:\n",
    "            raise Phishing_Exception(e,sys) from e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>artifact_timestamp</th>\n",
       "      <th>running_status</th>\n",
       "      <th>start_time</th>\n",
       "      <th>stop_time</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>message</th>\n",
       "      <th>custom_threshold</th>\n",
       "      <th>model_f1</th>\n",
       "      <th>model_recall</th>\n",
       "      <th>model_precision</th>\n",
       "      <th>is_model_accepted</th>\n",
       "      <th>created_time_stamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cd28b999-8eaa-416e-a9ef-2931b727f111</td>\n",
       "      <td>2022-10-02_01-04-39</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-10-02 01:04:40.823664</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pipeline has been started successfully</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-02 01:04:40.823664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>39ad3ddd-bef9-490b-b654-a33b230af192</td>\n",
       "      <td>2022-10-02_01-00-52</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-10-02 01:00:52.574855</td>\n",
       "      <td>2022-10-02 01:02:32.149114</td>\n",
       "      <td>0 days 00:01:39.574259</td>\n",
       "      <td>Pipeline has finished executing.</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.938431</td>\n",
       "      <td>0.975619</td>\n",
       "      <td>0.903974</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-10-02 01:02:32.150113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>39ad3ddd-bef9-490b-b654-a33b230af192</td>\n",
       "      <td>2022-10-02_01-00-52</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-10-02 01:00:52.574855</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pipeline has been started successfully</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-02 01:00:52.579760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25c3c86d-dfcc-48df-8125-39c1e59bd7a2</td>\n",
       "      <td>2022-10-02_00-58-01</td>\n",
       "      <td>False</td>\n",
       "      <td>2022-10-02 00:58:02.142238</td>\n",
       "      <td>2022-10-02 00:59:43.976844</td>\n",
       "      <td>0 days 00:01:41.834606</td>\n",
       "      <td>Pipeline has finished executing.</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.938696</td>\n",
       "      <td>0.976378</td>\n",
       "      <td>0.903815</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-10-02 00:59:43.977845</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>25c3c86d-dfcc-48df-8125-39c1e59bd7a2</td>\n",
       "      <td>2022-10-02_00-58-01</td>\n",
       "      <td>True</td>\n",
       "      <td>2022-10-02 00:58:02.142238</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Pipeline has been started successfully</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-10-02 00:58:02.142238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          experiment_id   artifact_timestamp  running_status  \\\n",
       "6  cd28b999-8eaa-416e-a9ef-2931b727f111  2022-10-02_01-04-39            True   \n",
       "5  39ad3ddd-bef9-490b-b654-a33b230af192  2022-10-02_01-00-52           False   \n",
       "4  39ad3ddd-bef9-490b-b654-a33b230af192  2022-10-02_01-00-52            True   \n",
       "3  25c3c86d-dfcc-48df-8125-39c1e59bd7a2  2022-10-02_00-58-01           False   \n",
       "2  25c3c86d-dfcc-48df-8125-39c1e59bd7a2  2022-10-02_00-58-01            True   \n",
       "\n",
       "                   start_time                   stop_time  \\\n",
       "6  2022-10-02 01:04:40.823664                         NaN   \n",
       "5  2022-10-02 01:00:52.574855  2022-10-02 01:02:32.149114   \n",
       "4  2022-10-02 01:00:52.574855                         NaN   \n",
       "3  2022-10-02 00:58:02.142238  2022-10-02 00:59:43.976844   \n",
       "2  2022-10-02 00:58:02.142238                         NaN   \n",
       "\n",
       "           execution_time                                 message  \\\n",
       "6                     NaN  Pipeline has been started successfully   \n",
       "5  0 days 00:01:39.574259        Pipeline has finished executing.   \n",
       "4                     NaN  Pipeline has been started successfully   \n",
       "3  0 days 00:01:41.834606        Pipeline has finished executing.   \n",
       "2                     NaN  Pipeline has been started successfully   \n",
       "\n",
       "   custom_threshold  model_f1  model_recall  model_precision  \\\n",
       "6               NaN       NaN           NaN              NaN   \n",
       "5               0.3  0.938431      0.975619         0.903974   \n",
       "4               NaN       NaN           NaN              NaN   \n",
       "3               0.3  0.938696      0.976378         0.903815   \n",
       "2               NaN       NaN           NaN              NaN   \n",
       "\n",
       "  is_model_accepted          created_time_stamp  \n",
       "6               NaN  2022-10-02 01:04:40.823664  \n",
       "5             False  2022-10-02 01:02:32.150113  \n",
       "4               NaN  2022-10-02 01:00:52.579760  \n",
       "3              True  2022-10-02 00:59:43.977845  \n",
       "2               NaN  2022-10-02 00:58:02.142238  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.get_experiments_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Checking the component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phishing_domain_detection.pipeline.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n",
      "c:\\Users\\rachi\\Desktop\\inueuron\\PERSONAL PROJECTS\\Phishing-Domain-Detection-using-Machine-Learning\\venv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning:\n",
      "\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipeline.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"phishing_domain_detection\\\\artifacts\\\\experiment\\\\experiment.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows_to_return = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df  = df.iloc[-1:(-1*rows_to_return)-1:-1].drop(columns=[\"experiment_file_path\", \"initialization_timestamp\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['experiment_id', 'artifact_timestamp', 'running_status', 'start_time', 'stop_time', 'execution_time', 'message', 'custom_threshold', 'model_f1', 'model_recall', 'model_precision', 'is_model_accepted', 'created_time_stamp'])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'experiment_file_path' in df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['experiment_id', 'artifact_timestamp', 'running_status', 'start_time', 'stop_time', 'execution_time', 'message', 'custom_threshold', 'model_f1', 'model_recall', 'model_precision', 'is_model_accepted', 'created_time_stamp'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for key, value in df.iterrows():\n",
    "   print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['26508b92-089d-47c1-81f4-f1639c0dbb22', '2022-10-03_02-55-02',\n",
       "       '2022-10-03_02-55-02', False, '2022-10-03 03:00:26.155365',\n",
       "       '2022-10-03 03:01:54.973121', '0 days 00:01:28.817756',\n",
       "       'Pipeline has finished executing.', 'experiment.csv', 0.3,\n",
       "       0.9389452394046356, 0.9760920168467948, 0.9045221695072626, False,\n",
       "       '2022-10-03 03:01:54.973121'], dtype=object)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3076e57f7e845b049a649ef4bfee429470fec951874b133ec4bf7644af5a1074"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
